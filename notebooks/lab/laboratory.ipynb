{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d79c4b3-3280-489f-ba2a-e9e13509ef55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luism\\anaconda3\\envs\\llm_questions\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http import models\n",
    "from typing import List, Dict\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pymupdf\n",
    "from package.models.document_stuffs import CustomDocument\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010f031a-b283-4dce-bfec-b55c154c8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(host=\"localhost\", port=6333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babd8762-a12c-4aa7-a2e1-a0fa6c3ead3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.create_collection(\n",
    "#     collection_name = \"test_collection\",\n",
    "#     vectors_config = models.VectorParams(size=100, distance=models.Distance.COSINE)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5afa2fb7-5f23-4bf6-8352-ba92379f49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e92817-e661-4441-b3e2-514d408659a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf\n",
    "# from collections import defaultdict\n",
    "# from typing import List, Dict\n",
    "\n",
    "# class CustomSection:\n",
    "#     def __init__(self, section_title, section_text):\n",
    "#         self.title = section_title\n",
    "#         self.text = section_text\n",
    "\n",
    "# class CustomPage:\n",
    "#     def __init__(self, page_number: int, page: pymupdf.Page, page_headings: List[str]):\n",
    "#         text = page.get_text(\"text\")\n",
    "#         image_list = page.get_images(full=True)\n",
    "#         self.just_text = text                                  # internal use for analysis\n",
    "#         self.page_number = page_number\n",
    "#         self.num_sections = len(page_headings)\n",
    "#         self.num_chars = len(text)\n",
    "#         self.num_images = len(image_list)\n",
    "#         self.sections = self._make_sections(text, page_headings)\n",
    "#         # images itself\n",
    "#         # page number\n",
    "#         # should have a text attribute and a sections attribute\n",
    "    \n",
    "#     def _make_sections(self, text: str, page_headings) -> List[CustomSection]:\n",
    "#         sections = defaultdict(list)\n",
    "#         lines = text.split(\"\\n\")\n",
    "#         current_heading = page_headings.pop(0)\n",
    "#         next_heading = page_headings.pop(0) if page_headings else None\n",
    "#         for line in lines:\n",
    "#             if next_heading and next_heading.split(\":\")[-1] in line:\n",
    "#                 current_heading = next_heading\n",
    "#                 next_heading = page_headings.pop(0) if page_headings else None\n",
    "#             sections[current_heading].append(line)\n",
    "#         page_headings += [current_heading] # here for overflow which we want\n",
    "#         return [CustomSection(title, \"\\n\".join(text)) for title, text in sections.items()]\n",
    "\n",
    "#     # =======================================\n",
    "#     #                  DUNDERS\n",
    "#     # =======================================\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.sections[idx]\n",
    "\n",
    "#     def __str__(self):\n",
    "#         s = \"\"\n",
    "#         for section in self.sections:\n",
    "#             s += section.title + \"\\n\"\n",
    "#         return f\"Page {self.page_number} of document. Has {len(self.sections)} sections: \\n\" + s\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return str(self)\n",
    "\n",
    "# class CustomDocument:\n",
    "#     def __init__(self, file_path):\n",
    "#         pymupdf_doc = self._load_pdf(file_path)\n",
    "#         labels: Dict[int, List[str]] = self._create_multilevel_headings(pymupdf_doc.get_toc())\n",
    "#         self.file_path = file_path\n",
    "#         self.metadata = pymupdf_doc.metadata\n",
    "#         self.pages = self._create_pages(labels, pymupdf_doc)\n",
    "        \n",
    "#     def _load_pdf(self, file_path: str) -> pymupdf.Document:\n",
    "#         \"\"\"Load pdfs\"\"\"\n",
    "#         pdf = pymupdf.open(file_path)\n",
    "#         return pdf\n",
    "\n",
    "#     def _create_multilevel_headings(self, table_of_content: List[List[int]]) -> Dict[int, List[str]]:\n",
    "#         \"\"\"given a pdf table of content we get a heading id to chunk properly\"\"\"\n",
    "#         page_mapping = defaultdict(list)\n",
    "#         current_heading = []\n",
    "#         for heading_level, heading_title, page_number in table_of_content: \n",
    "#             # check if the criterion is met\n",
    "#             if heading_level <= len(current_heading):\n",
    "#                 current_heading = current_heading[:heading_level - 1] # in the case of headinglevel = 1 it returns an empty list\n",
    "#             current_heading.append(heading_title)\n",
    "    \n",
    "#             # add the joined headers\n",
    "#             page_mapping[page_number].append(\":\".join(current_heading))\n",
    "            \n",
    "#         return page_mapping\n",
    "\n",
    "#     def _create_pages(self, labels: Dict[int, List[str]], doc: pymupdf.Document) -> List[CustomPage]:\n",
    "#         pages, page_headings = [], []\n",
    "#         for page_num, page in enumerate(doc):\n",
    "#             page_num += 1\n",
    "#             page_headings += labels.get(page_num, [\"Other\"])\n",
    "#             pages.append(CustomPage(page_num, page, page_headings)) # headings should go away once popped\n",
    "#         return pages\n",
    "        \n",
    "#     def get_full_text(self) -> str:\n",
    "#         \"\"\"Text I would need to do analysis and show end users\"\"\"\n",
    "#         full_text = []\n",
    "#         for page_num, page in enumerate(self.pages):\n",
    "#             page_num += 1\n",
    "#             full_text.append(f\"Page {page_num}:\")\n",
    "#             for section in page.sections:\n",
    "#                 full_text.append(section.text)\n",
    "#         return \"\\n\".join(full_text)\n",
    "#     # =======================================\n",
    "#     #                  DUNDERS\n",
    "#     # =======================================\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.pages[idx]\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return f\"PDF of {self.file_path}, has {len(self.pages)} pages. Use .metadata attribute to see more\"\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return str(self)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb04c556-9f91-4f58-b60c-9601ab1c62e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, text: str, metadata):\n",
    "        self.text = text\n",
    "        self.metadata = metadata\n",
    "        \n",
    "class CustomCharacterTextSplitter:\n",
    "    def __init__(self, num_chars: int = 256, overlap: int = 0):\n",
    "        self.num_chars = num_chars\n",
    "        self.overlap = overlap\n",
    "\n",
    "    def split_document(self, doc: pymupdf.Document) -> List[Chunk]:\n",
    "        chunks = []\n",
    "        section_md = []\n",
    "        page_number_md = []\n",
    "        remainder = 0\n",
    "        overflow = False\n",
    "        chunk_text = \"\"\n",
    "        for page in doc:\n",
    "            for section in page:\n",
    "                if overflow:\n",
    "                    window_end = remainder\n",
    "                    section_md.append(section.title) if section_md[-1] != section.title else None\n",
    "                    page_number_md.append(page.page_number) if page_number_md[-1] != page.page_number else None\n",
    "                else:\n",
    "                    window_end = self.num_chars\n",
    "                    section_md = [section.title]\n",
    "                    page_number_md = [page.page_number]\n",
    "                    \n",
    "                section_length = len(section)\n",
    "                window_start   = 0\n",
    "                \n",
    "                while window_start < section_length:\n",
    "                    chunk_text += section[window_start:window_end]\n",
    "                    chunk_metadata = {\"page\": tuple(page_number_md), \"section\": tuple(section_md)}\n",
    "                    \n",
    "                    if window_end > section_length:\n",
    "                        remainder = window_end - section_length\n",
    "                        overflow = True\n",
    "                        break\n",
    "                    else:\n",
    "                        chunks.append(Chunk(chunk_text, chunk_metadata))\n",
    "                        chunk_text = \"\"\n",
    "                        window_start = window_end - self.overlap\n",
    "                        window_end   += self.num_chars - self.overlap\n",
    "                        overflow = False\n",
    "\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d02243d8-a154-48b6-88ba-dbab2f33a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkVectorizer:\n",
    "    def __init__(self, model_name: str):\n",
    "        self._model = AutoModel.from_pretrained(model_name)\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    def vectorize(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a3c48e-4367-47ba-9c28-6dfe9abec0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_doc = CustomDocument(\"aiayn.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3c5ce85-9a5c-4fe3-8f31-011fa39be476",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = CustomCharacterTextSplitter(num_chars=512, overlap=0)\n",
    "chunks = splitter.split_document(custom_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec269dd-d100-41b1-a49b-d8ca634fc70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luism\\anaconda3\\envs\\llm_questions\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\luism\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "vectorizer = ChunkVectorizer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b394a0d-f990-43d8-abc7-dcecbf4649e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af8017-7c73-48c2-bbb5-89dded49e7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8218f0-0baf-4e99-b628-b22a3cb2a50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24addd20-3403-4719-b4f1-b6b3f51a64a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc7556-ea5a-4ce1-80de-201f462822e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41f001-2b87-47fc-ba1a-5933d2f5732b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572d3d8-af0a-407f-bdcd-e2b84bbf8467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e339-1614-45f2-bb1e-daf2f9b476c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bea48-67c4-40d0-bc91-82a041f1f5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page_number, page in enumerate(doc):\n",
    "    image_list = page.get_images(full=True)\n",
    "    images = []\n",
    "    \n",
    "    for img_index, img in enumerate(image_list):\n",
    "        # Get the XREF of the image\n",
    "        xref = img[0]\n",
    "        \n",
    "        # Extract the image bytes\n",
    "        base_image = doc.extract_image(xref)\n",
    "        \n",
    "        # Get the image bytes and metadata\n",
    "        image_bytes = base_image[\"image\"]\n",
    "        image_ext = base_image[\"ext\"]\n",
    "        \n",
    "        # Save the image as a file\n",
    "        image_filename = f\"image_page{page_number+1}_{img_index}.{image_ext}\"\n",
    "        with open(image_filename, \"wb\") as image_file:\n",
    "            image_file.write(image_bytes)\n",
    "        \n",
    "        # Append image data to the list\n",
    "        images.append({\n",
    "            \"image_index\": img_index,\n",
    "            \"image_filename\": image_filename,\n",
    "            \"image_bytes\": image_bytes,\n",
    "            \"image_extension\": image_ext\n",
    "        })\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
